{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def parse_coords(coords):\n",
    "    return [float(x) for x in coords.split('-')]\n",
    "\n",
    "def get_x(filename):\n",
    "    x_pd = pd.read_csv(filename, header=None)\n",
    "    x_pd_parsed = x_pd.applymap(parse_coords)\n",
    "    x_np = x_pd_parsed.to_numpy()\n",
    "    return np.array([[x for x in y] for y in x_np[:]])\n",
    "\n",
    "def get_y(filename):\n",
    "    x_pd = pd.read_csv(filename, header=None)\n",
    "    return x_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_x('data/train_x.csv')\n",
    "y = get_y('data/train_y.csv').reshape((-1))\n",
    "\n",
    "X_test = get_x('data/test_x.csv')\n",
    "y_test = get_y('data/test_y.csv').reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_path(verts, ax):\n",
    "    ax.axis('off')\n",
    "    \n",
    "    xs, ys = zip(*verts)\n",
    "    ax.plot(xs, ys, 'x--', lw=2, color='black', ms=10)\n",
    "\n",
    "    i=0\n",
    "    for x,y in verts:\n",
    "        rand_x,rand_y = np.random.rand(2)-0.5\n",
    "        ax.text(x+rand_x, y+rand_y, 'P'+str(i))\n",
    "        i += 1\n",
    "\n",
    "    min_x,max_x = np.min(verts[:,0]),np.max(verts[:,0])\n",
    "    min_y,max_y = np.min(verts[:,1]),np.max(verts[:,1])\n",
    "\n",
    "\n",
    "    ax.set_xlim(min_x - 1, max_x + 1)\n",
    "    ax.set_ylim(min_y - 1, max_y + 1)\n",
    "    \n",
    "def plot_many(samples, labels=None):\n",
    "    n = (samples.shape[0])\n",
    "    if n < 20 :\n",
    "        cols = 5\n",
    "        rows = int((n+4)/5)\n",
    "        fig = plt.figure(figsize=(cols * 4, rows * 4))\n",
    "    else :\n",
    "        cols = 8\n",
    "        rows = int((n+cols-1)/cols)\n",
    "        fig = plt.figure(figsize=(cols * 3, rows * 3))\n",
    "    \n",
    "    for i in range(n):\n",
    "        sub = fig.add_subplot(rows, cols, i + 1)\n",
    "        if labels is not None :\n",
    "            sub.title.set_text('y={0}'.format(labels[i]))\n",
    "        else :\n",
    "            sub.title.set_text('nolabel')\n",
    "        plot_path(samples[i], sub)\n",
    "\n",
    "n = 10\n",
    "plot_many(X[:n], y[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "#         self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        hidden = (torch.randn(1,sentence.shape[0],  self.hidden_dim), torch.randn(1,sentence.shape[0], self.hidden_dim))\n",
    "        lstm_out, _ = self.lstm(sentence, hidden)\n",
    "#         print(lstm_out.shape)\n",
    "        lstm_out = lstm_out[:,-1,:]\n",
    "#         print(lstm_out.shape)\n",
    "        tag_space = self.hidden2tag(lstm_out)\n",
    "#         print(tag_space.shape)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "#         print(tag_scores.shape)\n",
    "        return tag_scores\n",
    "\n",
    "n_hidden = 256\n",
    "n_letters = 2\n",
    "n_categories = 4\n",
    "\n",
    "model = Net(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9000, 5, 2])\n",
      "5\n",
      "tensor([[-1.4309, -1.3221, -1.3003, -1.5056],\n",
      "        [-1.4772, -1.3053, -1.3434, -1.4285]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "\n",
    "Xt = to_tensor(X).float().permute(1,2,0)\n",
    "print(Xt.shape)\n",
    "inp = Xt[0:2,:,:]\n",
    "print(inp.shape[1])\n",
    "# print(inp.shape)\n",
    "output = model(inp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4537, -1.3515, -1.2742, -1.4793]])\n",
      "tensor([0])\n",
      "tensor(1.4537)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.004)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    row = Xt[0:1]\n",
    "    sentence_in = row\n",
    "    tag_scores = model(sentence_in)\n",
    "    print(tag_scores)\n",
    "    targets = torch.tensor(y[0:1], dtype=torch.long)\n",
    "    print(targets)\n",
    "    los = loss_function(tag_scores, targets)\n",
    "    print(los)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first step done\n",
      "epoch 0 loss 7254.806714057922\n",
      "epoch 1 loss 7172.887195944786\n",
      "epoch 2 loss 7066.885206699371\n",
      "epoch 3 loss 7073.397288322449\n",
      "epoch 4 loss 6949.938957095146\n",
      "epoch 5 loss 6934.847062826157\n",
      "epoch 6 loss 6872.2979056835175\n",
      "epoch 7 loss 6834.140741229057\n",
      "epoch 8 loss 6806.653291583061\n",
      "epoch 9 loss 6735.151392817497\n",
      "epoch 10 loss 6773.3903431892395\n",
      "epoch 11 loss 6770.376065969467\n",
      "epoch 12 loss 6720.105847120285\n",
      "epoch 13 loss 6713.281964063644\n",
      "epoch 14 loss 6700.487424731255\n",
      "epoch 15 loss 6682.895003557205\n",
      "epoch 16 loss 6665.949520468712\n",
      "epoch 17 loss 6663.55948984623\n",
      "epoch 18 loss 6619.430344104767\n",
      "epoch 19 loss 6583.683251738548\n",
      "epoch 20 loss 6578.1643760204315\n",
      "epoch 21 loss 6578.550233244896\n",
      "epoch 22 loss 6560.445676445961\n",
      "epoch 23 loss 6571.67999625206\n",
      "epoch 24 loss 6533.504077792168\n",
      "epoch 25 loss 6520.837415456772\n",
      "epoch 26 loss 6529.36961889267\n",
      "epoch 27 loss 6520.620376467705\n",
      "epoch 28 loss 6506.507440209389\n",
      "epoch 29 loss 6478.392975926399\n",
      "epoch 30 loss 6482.143964767456\n",
      "epoch 31 loss 6449.242191910744\n",
      "epoch 32 loss 6463.451360464096\n",
      "epoch 33 loss 6460.296873450279\n",
      "epoch 34 loss 6458.5050719976425\n",
      "epoch 35 loss 6488.004698753357\n",
      "epoch 36 loss 6414.816505908966\n",
      "epoch 37 loss 6405.19214451313\n",
      "epoch 38 loss 6393.900972604752\n",
      "epoch 39 loss 6397.757624387741\n",
      "epoch 40 loss 6406.846482753754\n",
      "epoch 41 loss 6424.888179302216\n",
      "epoch 42 loss 6370.195008516312\n",
      "epoch 43 loss 6371.2087869644165\n",
      "epoch 44 loss 6379.395178556442\n",
      "epoch 45 loss 6338.458821773529\n",
      "epoch 46 loss 6360.231610536575\n",
      "epoch 47 loss 6336.225786209106\n",
      "epoch 48 loss 6293.457421660423\n",
      "epoch 49 loss 6324.948368668556\n",
      "epoch 50 loss 6295.1284968853\n",
      "epoch 51 loss 6324.940869212151\n",
      "epoch 52 loss 6339.851580262184\n",
      "epoch 53 loss 6245.619102716446\n",
      "epoch 54 loss 6316.186101436615\n",
      "epoch 55 loss 6308.346959352493\n",
      "epoch 56 loss 6270.837934613228\n",
      "epoch 57 loss 6227.341779470444\n",
      "epoch 58 loss 6272.977371811867\n",
      "epoch 59 loss 6250.590008497238\n",
      "epoch 60 loss 6236.365138292313\n",
      "epoch 61 loss 6237.110508084297\n",
      "epoch 62 loss 6185.729897618294\n",
      "epoch 63 loss 6217.589390873909\n",
      "epoch 64 loss 6232.554851174355\n",
      "epoch 65 loss 6195.123079419136\n",
      "epoch 66 loss 6251.0684180259705\n",
      "epoch 67 loss 6184.206156134605\n",
      "epoch 68 loss 6171.785082221031\n",
      "epoch 69 loss 6153.389693498611\n",
      "epoch 70 loss 6200.9062063694\n",
      "epoch 71 loss 6142.360589504242\n",
      "epoch 72 loss 6121.019985079765\n",
      "epoch 73 loss 6122.793472409248\n",
      "epoch 74 loss 6150.290776491165\n",
      "epoch 75 loss 6140.807000398636\n",
      "epoch 76 loss 6084.1085511446\n",
      "epoch 77 loss 6110.365317463875\n",
      "epoch 78 loss 6079.3184369802475\n",
      "epoch 79 loss 6020.932958722115\n",
      "epoch 80 loss 6115.541358590126\n",
      "epoch 81 loss 6067.742972373962\n",
      "epoch 82 loss 6034.632480740547\n",
      "epoch 83 loss 6057.377817034721\n",
      "epoch 84 loss 6059.919746518135\n",
      "epoch 85 loss 6018.703479766846\n",
      "epoch 86 loss 6008.829147219658\n",
      "epoch 87 loss 5977.443552017212\n",
      "epoch 88 loss 6045.355287194252\n",
      "epoch 89 loss 6008.04939687252\n",
      "epoch 90 loss 5964.053653478622\n",
      "epoch 91 loss 5994.096336364746\n",
      "epoch 92 loss 6028.38703751564\n",
      "epoch 93 loss 5976.561099886894\n",
      "epoch 94 loss 5924.943371415138\n",
      "epoch 95 loss 5953.464034795761\n",
      "epoch 96 loss 5954.970535039902\n",
      "epoch 97 loss 5917.675443291664\n",
      "epoch 98 loss 5995.981473326683\n",
      "epoch 99 loss 5985.94261944294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f005ccfe210>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "batch_size = 100\n",
    "batches = int(len(Xt)/batch_size)\n",
    "\n",
    "for i in range(batches) :\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        n = i * batch_size\n",
    "        sentence_in = Xt[n:n+batch_size,:4,:]\n",
    "        targets = torch.tensor(y[n:n+batch_size], dtype=torch.long)\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "#         acc_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(\"first step done\")\n",
    "\n",
    "\n",
    "for epoch in range(100):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    acc_loss = 0\n",
    "    \n",
    "    for i in range(batches) :\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        n = i * batch_size\n",
    "        sentence_in = Xt[n:n+batch_size]\n",
    "        targets = torch.tensor(y[n:n+batch_size], dtype=torch.long)\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        acc_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_log.append(acc_loss)\n",
    "    if epoch % 10 == 0 :\n",
    "        print(\"epoch\", epoch, \"loss\", acc_loss*batches)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_log, label='truncated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1971, -2.4941, -2.3861, -5.4374]])\n",
      "tensor([0])\n",
      "tensor(0.1971)\n"
     ]
    }
   ],
   "source": [
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    row = Xt[:1]\n",
    "    sentence_in = row\n",
    "    tag_scores = model(sentence_in)\n",
    "    print(tag_scores)\n",
    "    targets = torch.tensor(y[0:1], dtype=torch.long)\n",
    "    print(targets)\n",
    "    los = loss_function(tag_scores, targets)\n",
    "    print(los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9000, 4])\n",
      "torch.Size([9000])\n",
      "acc: 0.7017777562141418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7017777562141418"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(testX, testY):\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "    with torch.no_grad():\n",
    "        tag_scores = model(testX)\n",
    "        print(tag_scores.shape)\n",
    "        targets = torch.tensor(testY, dtype=torch.long)\n",
    "        print(targets.shape)\n",
    "            \n",
    "    acc = ((tag_scores.argmax(dim=1) == targets).sum().float()/float(testY.shape[0])).item()\n",
    "    print('acc:', acc)\n",
    "    return acc\n",
    "\n",
    "accuracy(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9000, 4])\n",
      "torch.Size([9000])\n",
      "torch.Size([9000])\n",
      "tensor([0, 1, 3, 2, 1])\n",
      "tensor([0, 1, 3, 3, 3])\n",
      "tensor(0.6000)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        tag_scores = model(Xt)\n",
    "        print(tag_scores.shape)\n",
    "        print(tag_scores.argmax(dim=1).shape)\n",
    "        targets = torch.tensor(y, dtype=torch.long)\n",
    "        print(targets.shape)\n",
    "        print(tag_scores.argmax(dim=1)[:5])\n",
    "        print(targets[:5])\n",
    "        print((tag_scores.argmax(dim=1) == targets)[:5].sum()/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9000, 4])\n",
      "torch.Size([9000])\n",
      "acc: 0.6769999861717224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6769999861717224"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 4])\n",
      "torch.Size([1000])\n",
      "acc: 0.6549999713897705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6549999713897705"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tens = to_tensor(X_test).float().permute(1,2,0)\n",
    "accuracy(X_test_tens, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
